{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b990f-e6d7-43cc-b6ff-57292a750373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% md\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/cedjustin/AI/blob/master/Sprint23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "#%% md\n",
    "\n",
    "# 問題1　各種手法の実行\n",
    "\n",
    "#%% md\n",
    "\n",
    "## ①SimpleRNN\n",
    "\n",
    "#%%\n",
    "\n",
    "# ライブラリのimport \n",
    "from __future__ import print_function\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "\n",
    "#%%\n",
    "\n",
    "# imdbデータの読み込みと整形\n",
    "max_features = 20000\n",
    "maxlen = 80\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "# 確認\n",
    "x_train.shape, y_train.shape,x_test.shape, y_test.shape\n",
    "\n",
    "#%%\n",
    "\n",
    "# モデルの定義\n",
    "# Embeddingに関して：https://kento1109.hatenablog.com/entry/2017/12/02/114515\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#%%\n",
    "\n",
    "# コンパイルと学習\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=1,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "#%%\n",
    "\n",
    "# 評価\n",
    "score, acc = model.evaluate(\n",
    "    x_test, \n",
    "    y_test,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "#%% md\n",
    "\n",
    "# ②SimpleRNN\n",
    "\n",
    "#%%\n",
    "\n",
    "# ライブラリのimport\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "\n",
    "#%%\n",
    "\n",
    "# imdbデータの読み込みと整形\n",
    "max_features = 20000\n",
    "maxlen = 80\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "# 確認\n",
    "x_train.shape, y_train.shape,x_test.shape, y_test.shape\n",
    "\n",
    "#%%\n",
    "\n",
    "# モデルの定義\n",
    "# Embeddingに関して：https://kento1109.hatenablog.com/entry/2017/12/02/114515\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#%%\n",
    "\n",
    "# コンパイルと学習\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=1,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "#%%\n",
    "\n",
    "# 評価\n",
    "score, acc = model.evaluate(\n",
    "    x_test, \n",
    "    y_test,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "#%% md\n",
    "\n",
    "# ③GRU\n",
    "\n",
    "#%%\n",
    "\n",
    "# ライブラリのimport\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "\n",
    "#%%\n",
    "\n",
    "# imdbデータの読み込みと整形\n",
    "max_features = 20000\n",
    "maxlen = 80\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "# 確認\n",
    "x_train.shape, y_train.shape,x_test.shape, y_test.shape\n",
    "\n",
    "#%%\n",
    "\n",
    "# モデルの定義\n",
    "# Embeddingに関して：https://kento1109.hatenablog.com/entry/2017/12/02/114515\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#%%\n",
    "\n",
    "# コンパイルと学習\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=1,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "#%%\n",
    "\n",
    "# 評価\n",
    "score, acc = model.evaluate(\n",
    "    x_test, \n",
    "    y_test,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "#%% md\n",
    "\n",
    "# ④ConvLSTM2D\n",
    "\n",
    "#%%\n",
    "\n",
    "# ライブラリのimport\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from keras import backend as K\n",
    "%matplotlib notebook\n",
    "if K.backend() == 'mxnet':\n",
    "    raise NotImplementedError(\"MXNet Backend: ConvLSTM2D Layer is not supported yet.\")\n",
    "\n",
    "#%%\n",
    "\n",
    "# データ作成\n",
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    \"\"\"テスト動画作成関数（理解不要）\n",
    "    Parameters\n",
    "    -----------\n",
    "    n_samples : 動画数 \n",
    "    n_frames : フレーム数\n",
    "    \"\"\"\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
    "                              dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
    "                             y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the network to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1)**np.random.randint(0, 2)\n",
    "                    noisy_movies[i, t,\n",
    "                                 x_shift - w - 1: x_shift + w + 1,\n",
    "                                 y_shift - w - 1: y_shift + w + 1,\n",
    "                                 0] += noise_f * 0.1\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
    "                               y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies\n",
    "\n",
    "# 上記関数実行\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
    "\n",
    "#%%\n",
    "\n",
    "# どのようなデータが生成されているか出力\n",
    "# データ選択\n",
    "index = 1\n",
    "x= noisy_movies[index]\n",
    "\n",
    "# 描画\n",
    "fig= plt.figure()\n",
    "viewer= fig.add_subplot(111)\n",
    "plt.ion()\n",
    "fig.show()\n",
    "for i in range(len(x)):\n",
    "    viewer.clear()\n",
    "    viewer.imshow(x[i])\n",
    "    plt.pause(.1)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "#%%\n",
    "\n",
    "# モデルの定義とコンパイル\n",
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   input_shape=(None, 40, 40, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last'))\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "\n",
    "seq.summary()\n",
    "\n",
    "#%%\n",
    "\n",
    "# 学習\n",
    "seq.fit(\n",
    "    noisy_movies[:100], \n",
    "    shifted_movies[:100], \n",
    "    batch_size=10,\n",
    "    epochs=1, \n",
    "    validation_split=0.05\n",
    ")\n",
    "\n",
    "#%%\n",
    "\n",
    "# テスト用データ取得\n",
    "which = 1004\n",
    "track = noisy_movies[which][:7, ::, ::, ::] # 7フレームまで取得\n",
    "track2 = noisy_movies[which][::, ::, ::, ::] # 正解データ\n",
    "\n",
    "# 予測\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)\n",
    "\n",
    "# 描画\n",
    "track2 = noisy_movies[which][::, ::, ::, ::]\n",
    "for i in range(15):\n",
    "    # 初期化\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    ## 予測値描画\n",
    "    ax = fig.add_subplot(121)\n",
    "    # テキスト\n",
    "    if i >= 7:\n",
    "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
    "    else:\n",
    "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
    "    # 描画\n",
    "    toplot = track[i, ::, ::, 0]\n",
    "    plt.imshow(toplot)\n",
    "    \n",
    "    ## 実測値描画\n",
    "    ax = fig.add_subplot(122)\n",
    "    # テキスト\n",
    "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
    "    # 描画\n",
    "    toplot = track2[i, ::, ::, 0]\n",
    "    if i >= 2:\n",
    "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
    "    plt.imshow(toplot)\n",
    "    \n",
    "    ## 保存\n",
    "    plt.savefig('%i_animate.png' % (i + 1))\n",
    "\n",
    "#%% md\n",
    "\n",
    "# 問題3　他のクラスの説明\n",
    "\n",
    "- RNN リカレントニューラルネットワーク（RNN）とは、ノード間の接続が時間的な順序に沿った有向グラフを形成する人工ニューラルネットワークのクラスです。\n",
    "\n",
    "- SimpleRNNCell：SimpleRNNのCellクラスです。セルは、再帰的に現れる同じネットワーク構造です。\n",
    "\n",
    "- GRUCell: LSTMを簡略化したゲートを持つ再帰的なユニットであるgru layerのセルクラスです。\n",
    "\n",
    "- LSTMCell: 基本的にはLSTM層用のCellクラスで、1ステップ分の計算ロジックを含んでいます\n",
    "\n",
    "- StackedRNNCells: RNNセルスタックの動作を単一セルのように見せるためのラッパーです。\n",
    "\n",
    "- CuDNNGRU：CuDNNを使った高速GRUの実装です。\n",
    "\n",
    "- CuDNNLSTM：CuDNNを用いた高速なLSTM実装です。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
