{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7777296d-4c58-4ef6-8e08-e06aa08125a8",
   "metadata": {},
   "source": [
    "ニューラルネットワークは本来「網」なので、要素であるニューロン（神経）が文字通り網の目状に絡まっています。ただそういう構造は複雑で作る事が難しいため、構造（モデル）を簡略化します。その一つのモデルがシーケンシャル（Sequential）モデルです。シーケンシャルというのは「線形の」という意味で、線形というのは線のように一列につながっているという事です。その繋がる元は「レイヤー(Layer)」と呼ばれているニューロン（パーセプトロン（Perseptron））の塊です：\n",
    "　レイヤーの中にあるパーセプトロンが次のレイヤーに信号を送る。これをシーケンシャルに続けていき、最後のレイヤーまで届ける。この割と単純なモデルがシーケンシャルモデルです。Sequentialモデルにはこのレイヤーをいくらでも直列に追加する事が出来ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02ef0831-64ce-4deb-b5f0-5396bf98d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba8146ea-8cb6-4863-b443-f8c99fc9dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取り込み\n",
    "train = pd.read_csv(\"titanic_train.csv\")\n",
    "test = pd.read_csv(\"titanic_test.csv\")\n",
    "data_check = pd.read_csv(\"titanic_gender_submission.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# 列削除\n",
    "train_x = train.drop([\"Survived\", \"Name\", \"Cabin\", \"Ticket\", \"PassengerId\"], axis=1)\n",
    "test_x = test.drop([\"Name\", \"Cabin\", \"Ticket\", \"PassengerId\"], axis=1)\n",
    "\n",
    "\n",
    "# Survived列のみ抽出\n",
    "train_y = train[\"Survived\"]\n",
    "\n",
    "\n",
    "# 欠損値を年齢の中央値。出港地は最多のSで補完\n",
    "train_x[\"Age\"] = train_x[\"Age\"].fillna(train_x[\"Age\"].median())\n",
    "train_x[\"Embarked\"] = train_x[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "test_x[\"Age\"] = test_x[\"Age\"].fillna(test_x[\"Age\"].median())\n",
    "test_x[\"Fare\"] = test_x[\"Fare\"].fillna(test_x[\"Fare\"].median())\n",
    "test_x[\"Embarked\"] = test_x[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "\n",
    "# Sex、Embarked列をダミー変換\n",
    "train_x_dummy = pd.get_dummies(train_x,columns=[\"Sex\",\"Embarked\"])\n",
    "test_x_dummy = pd.get_dummies(test_x,columns=[\"Sex\",\"Embarked\"])\n",
    "\n",
    "\n",
    "# 説明変数、目的変数分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x_dummy, train_y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924e43df-1736-492b-a294-d4e6ed487486",
   "metadata": {},
   "source": [
    "# Kerasを用いてtitanic生存予測<br>\n",
    "\n",
    "①<br>\n",
    "② ①　＋　Batch Normalization：バッチ正規化<br>\n",
    "③ ②　＋　Dropout<br>\n",
    "④ ③　＋　L2正則化<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d3db36a-4bce-4c7f-b9c3-ec76a8bc56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ①バッチサイズ、イテレーション数、エポック数\n",
    "\n",
    "\n",
    "import keras\n",
    "# from keras.modelsというのはモデルが色々はいったモジュール。その中から「Sequentialを使う」というのがimport Sequential\n",
    "from keras.models import Sequential\n",
    "# レイヤーはkeras.layersにまとめられていて、その中のDenseを使う事を上で宣言\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# Sequentialが持っているaddメソッドでレイヤーを追加\n",
    "# addメソッドの引数にDenseレイヤーを与える\n",
    "# Denseレイヤーも多様なパラメータで初期化できるのですが、最も単純な初期化が上のようにunitsに数値を与えるだけのもの\n",
    "# unitsはDenseを作る時に唯一必須のパラメータ\n",
    "# Denseクラスは「ニューロンは次の層にあるあらゆるニューロンに全部連結する」という全連結層を作る時に使う\n",
    "#　Denseは全結合するので、上のSequentialモデルの各レイヤーのユニットは次のユニットにすべて繋がる\n",
    "# 入力シェイプ（input_shape）　N次元のデータ\n",
    "model.add(Dense(units = 16, input_shape = (X_train.shape[1], )))\n",
    "model.add(Dense(units = 24, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "model.add(Dense(units = 1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# 平均二乗誤差（Mean squared error）, 重み更新方法の変更　：　確率的勾配降下法（Stochastic gradient descent）\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics=['accuracy'])\n",
    "\n",
    "model.fit( X_train, y_train, epochs = 500, batch_size = 30 , verbose=0)\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test, batch_size = 5)\n",
    "np.set_printoptions(suppress=True)\n",
    "predictions\n",
    "\n",
    "# 2値分類のうちどちらに分類されるか\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "046fb0fa-50e0-400d-b28b-fc6bf1409873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[124  30]\n",
      " [ 33  81]]\n",
      "accuracy =  0.7649253731343284\n",
      "precision =  0.7297297297297297\n",
      "recall =  0.7105263157894737\n",
      "f1 score =  0.7200000000000001\n"
     ]
    }
   ],
   "source": [
    "# 真陽性（TP: True Positive）: 実際のクラスが陽性で予測も陽性（正解）\n",
    "# 真陰性（TN: True Negative）: 実際のクラスが陰性で予測も陰性（正解）\n",
    "# 偽陽性（FP: False Positive）: 実際のクラスは陰性で予測が陽性（不正解）\n",
    "# 偽陰性（FN: False Negative）: 実際のクラスは陽性で予測が陰性（不正解）\n",
    "\n",
    "# クラス分類問題における評価指標\n",
    "# 正解率（accuracy）: accuracy_score()\n",
    "# 適合率（precision）: precision_score()\n",
    "# 再現率（recall）: recall_score()\n",
    "# F1値（F1-measure）: f1_score()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('confusion matrix = \\n', confusion_matrix(y_test, y_pred))\n",
    "print('accuracy = ', accuracy_score(y_test, y_pred))\n",
    "print('precision = ', precision_score(y_test, y_pred))\n",
    "print('recall = ', recall_score(y_test, y_pred))\n",
    "print('f1 score = ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33edc745-855a-4a56-8459-569b392ea896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ②Batch Normalization：バッチ正規化\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "from keras.layers import Dense, BatchNormalization, Activation\n",
    "\n",
    "model.add(Dense(units = 16, input_shape = (X_train.shape[1], )))\n",
    "model.add(Dense(units = 24, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Batch Normalization：バッチ正規化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(units = 1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# 平均二乗誤差（Mean squared error）, 重み更新方法の変更　：　確率的勾配降下法（Stochastic gradient descent）\n",
    "# sgd = optimizers.SGD( learning_rate=0.001 ) \n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics=['accuracy'])\n",
    "\n",
    "model.fit( X_train, y_train, epochs = 500, batch_size = 30 , verbose=0)\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test, batch_size = 5)\n",
    "np.set_printoptions(suppress=True)\n",
    "predictions\n",
    "\n",
    "# 2値分類のうちどちらに分類されるか\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "237a4cdd-7cd4-4895-a101-937330edf386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[130  24]\n",
      " [ 40  74]]\n",
      "accuracy =  0.7611940298507462\n",
      "precision =  0.7551020408163265\n",
      "recall =  0.6491228070175439\n",
      "f1 score =  0.6981132075471698\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_test, y_pred))\n",
    "print('accuracy = ', accuracy_score(y_test, y_pred))\n",
    "print('precision = ', precision_score(y_test, y_pred))\n",
    "print('recall = ', recall_score(y_test, y_pred))\n",
    "print('f1 score = ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8540e6c7-8d51-4eb1-b1a8-d2fe76703871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ③Dropout\n",
    "\n",
    "from keras.layers import Dense, BatchNormalization, Activation\n",
    "\n",
    "model.add(Dense(units = 16, input_shape = (X_train.shape[1], )))\n",
    "model.add(Dense(units = 24, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Batch Normalization：バッチ正規化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(units = 1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# 平均二乗誤差（Mean squared error）, 重み更新方法の変更　：　確率的勾配降下法（Stochastic gradient descent）\n",
    "# sgd = optimizers.SGD( learning_rate=0.001 ) \n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics=['accuracy'])\n",
    "\n",
    "model.fit( X_train, y_train, epochs = 500, batch_size = 30 , verbose=0)\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test, batch_size = 5)\n",
    "np.set_printoptions(suppress=True)\n",
    "predictions\n",
    "\n",
    "# 2値分類のうちどちらに分類されるか\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae1d0450-14cd-4c2d-9696-9d61e245659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[143  11]\n",
      " [ 50  64]]\n",
      "accuracy =  0.7723880597014925\n",
      "precision =  0.8533333333333334\n",
      "recall =  0.5614035087719298\n",
      "f1 score =  0.6772486772486772\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_test, y_pred))\n",
    "print('accuracy = ', accuracy_score(y_test, y_pred))\n",
    "print('precision = ', precision_score(y_test, y_pred))\n",
    "print('recall = ', recall_score(y_test, y_pred))\n",
    "print('f1 score = ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ecfd0d0-65b9-4a6c-9217-19da9e5e87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ④正則化\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "model.add(Dense(units = 16, kernel_regularizer=regularizers.l2(0.001), input_shape = (X_train.shape[1], )))\n",
    "model.add(Dense(units = 24, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Batch Normalization：バッチ正規化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(units = 1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# 平均二乗誤差（Mean squared error）, 重み更新方法の変更　：　確率的勾配降下法（Stochastic gradient descent）\n",
    "# sgd = optimizers.SGD( learning_rate=0.001 ) \n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics=['accuracy'])\n",
    "\n",
    "model.fit( X_train, y_train, epochs = 500, batch_size = 30 , verbose=0)\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test, batch_size = 5)\n",
    "np.set_printoptions(suppress=True)\n",
    "predictions\n",
    "\n",
    "# 2値分類のうちどちらに分類されるか\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3705d15d-a809-42cc-8401-855cc5bdd22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[140  14]\n",
      " [ 45  69]]\n",
      "accuracy =  0.7798507462686567\n",
      "precision =  0.8313253012048193\n",
      "recall =  0.6052631578947368\n",
      "f1 score =  0.700507614213198\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_test, y_pred))\n",
    "print('accuracy = ', accuracy_score(y_test, y_pred))\n",
    "print('precision = ', precision_score(y_test, y_pred))\n",
    "print('recall = ', recall_score(y_test, y_pred))\n",
    "print('f1 score = ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196f461-cf06-45dd-a207-c4cb64cb0410",
   "metadata": {},
   "source": [
    "①\n",
    "confusion matrix = <br>\n",
    " [[124  30]<br>\n",
    " [ 33  81]]<br>\n",
    "accuracy =  0.7649253731343284<br>\n",
    "precision =  0.7297297297297297<br>\n",
    "recall =  0.7105263157894737<br>\n",
    "f1 score =  0.7200000000000001<br>\n",
    "\n",
    "②<br>\n",
    "confusion matrix = <br>\n",
    " [[130  24]<br>\n",
    " [ 40  74]]<br>\n",
    "accuracy =  0.7611940298507462<br>\n",
    "precision =  0.7551020408163265<br>\n",
    "recall =  0.6491228070175439<br>\n",
    "f1 score =  0.6981132075471698<br>\n",
    "\n",
    "③<br>\n",
    "confusion matrix = <br>\n",
    " [[143  11]<br>\n",
    " [ 50  64]]<br>\n",
    "accuracy =  0.7723880597014925<br>\n",
    "precision =  0.8533333333333334<br>\n",
    "recall =  0.5614035087719298<br>\n",
    "f1 score =  0.6772486772486772<br>\n",
    "\n",
    "④<br>\n",
    "confusion matrix = <br>\n",
    " [[140  14]<br>\n",
    " [ 45  69]]<br>\n",
    "accuracy =  0.7798507462686567<br>\n",
    "precision =  0.8313253012048193<br>\n",
    "recall =  0.6052631578947368<br>\n",
    "f1 score =  0.700507614213198<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b53897-2be7-4b7d-b9d8-65c55786c95f",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4e33536-5994-4020-bc25-43c690c0f86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[ 99.88799]\n",
      " [499.40933]]\n"
     ]
    }
   ],
   "source": [
    "#モデル作成\n",
    "model = Sequential()\n",
    "model.add( InputLayer( input_shape = ( 1, ) ) )\n",
    "model.add( Dense( 1, activation='relu' ) )\n",
    "sgd = optimizers.SGD( learning_rate=0.001 ) # learning_rate(学習率)の設定は大切！\n",
    "model.compile( loss = 'mse', optimizer = sgd, metrics=[\"accuracy\"] )\n",
    "\n",
    "#概略表示\n",
    "model.summary()\n",
    "\n",
    "#訓練開始\n",
    "train_x0 = numpy.array( [ 10, 14, 8, 16 ] )\n",
    "train_x1 = numpy.array( [ 5, 7, 4, 8 ] )\n",
    "history = model.fit( train_x0, train_x1, epochs = 30, verbose=0) #epochs(繰り返し数)大切\n",
    "\n",
    "#実用テスト\n",
    "test_x0 = numpy.array( [ 200, 1000 ] )\n",
    "res = model.predict( test_x0 )\n",
    "print( res )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ea49a48-62d1-4d41-93ae-d29d44f53cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[140  14]\n",
      " [ 45  69]]\n",
      "accuracy =  0.7798507462686567\n",
      "precision =  0.8313253012048193\n",
      "recall =  0.6052631578947368\n",
      "f1 score =  0.700507614213198\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_test, y_pred))\n",
    "print('accuracy = ', accuracy_score(y_test, y_pred))\n",
    "print('precision = ', precision_score(y_test, y_pred))\n",
    "print('recall = ', recall_score(y_test, y_pred))\n",
    "print('f1 score = ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92927151-d614-47ae-96d2-90b105f630ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# 正則化　kernel_regularizer=keras.regularizers.l1\n",
    "\n",
    "#モデル作成\n",
    "model = Sequential()\n",
    "model.add( keras.layers.Dense( units=100, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(0.01), input_shape=(1,) ) )\n",
    "\n",
    "model.add( Dense( 1, activation='relu' ) )\n",
    "sgd = optimizers.SGD( learning_rate=0.001 ) # learning_rate(学習率)の設定は大切！\n",
    "model.compile( loss = 'mse', optimizer = sgd, metrics=[\"accuracy\"] )\n",
    "\n",
    "#概略表示\n",
    "model.summary()\n",
    "\n",
    "#訓練開始\n",
    "train_x0 = numpy.array( [ 10, 14, 8, 16 ] )\n",
    "train_x1 = numpy.array( [ 5, 7, 4, 8 ] )\n",
    "history = model.fit( train_x0, train_x1, epochs = 30, verbose=0) #epochs(繰り返し数)大切\n",
    "\n",
    "#実用テスト\n",
    "test_x0 = numpy.array( [ 200, 1000 ] )\n",
    "res = model.predict( test_x0 )\n",
    "print( res )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
