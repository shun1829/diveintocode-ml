{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 【問題1】仮定関数\n",
    "クラスの外から呼び出すことがないメソッドのため、\n",
    "Pythonの慣例としてアンダースコアを先頭にひとつつけています。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def _linear_hypothesis(self, theta):  # 必要に応じて引数を追加して下さい\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    self.coef_ : theta(coefficient) 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "    \"\"\"\n",
    "    # X.shape(n_samples, n_features) shape[0]で行数取得,shape[1]で列数取得\n",
    "    n_samples = X.shape[0]\n",
    "    n_features = X.shape[1]\n",
    "    # Xの(n_samples, 1) のshapeの1のみの行列を作る\n",
    "    one_array = np.ones((n_samples, 1))\n",
    "    # Xの一列目にone_arrayを結合\n",
    "    one_X = np.concatenate([one_array, X], axis=1)\n",
    "    # one_Xの特徴量数の1のみの行列を作る(n_features+1, 1) shape[1]で列数取得\n",
    "    theta = np.ones((one_X.shape[1], 1))\n",
    "\n",
    "    y_hat = one_X @ theta\n",
    "\n",
    "    return y_hat, theta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 【問題2】最急降下法\n",
    "以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、\n",
    "fitメソッドから呼び出すようにしてください。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def _gradient_descent(self):\n",
    "    # _gradient_descent(self, X, y_hat, y_true, alpha= , one_X, n_samples):\n",
    "    \"\"\"\n",
    "    最急降下法によるパラメータの更新値計算\n",
    "    Parameters\n",
    "    ----------\n",
    "    α: 学習率\n",
    "    i : サンプルのインデックス\n",
    "    j : 特徴量のインデックス\n",
    "    lr : alfa アルファ　学習率(learning rate)\n",
    "    self.coef_ : theta(coefficient) 次の形のndarray, shape (n_features,)\n",
    "    Returns\n",
    "    -------\n",
    "    theta\n",
    "    \"\"\"\n",
    "    # y_hatは　_linear_hypothesisのreturnを予定　\n",
    "    # y_trueはどこかの正解値\n",
    "    # alphaはスカラー\n",
    "    error = y_hat - y_true\n",
    "    # one_Xは　Xの1列目に1のみの列を結合させてある\n",
    "    theta = theta - (alfa / n_samples) * (error.T @ one_X).T\n",
    "\n",
    "    return theta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 【問題3】推定\n",
    "推定する仕組みを実装してください。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 【問題4】平均二乗誤差\n",
    "別の関数として作成してください。雛形を用意してあります。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 【問題5】目的関数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 【問題6】学習と推定"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 【問題7】学習曲線のプロット"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, no_bias=True, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.losses = np.array([])\n",
    "        self.losses_val = np.array([])\n",
    "        self.theta = None\n",
    "\n",
    "    # 問題6（学習と推定）\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        \"\"\"\n",
    "        # self.n_samples = X.shape[0]\n",
    "        # n_features = X.shape[1]\n",
    "\n",
    "        self.theta = np.ones((X.shape[1]+1, 1)) # 1の配列でthetaを作成。shape(X.shape[1]+1, 1)\n",
    "        one_array = np.ones((X.shape[0], 1)) # bias項サンプル数分作成\n",
    "        one_X = np.concatenate([one_array, X], axis=1) # Xとbias項を結合\n",
    "\n",
    "\n",
    "        one_X_val = None # これがないと　# 「損失計算と記録内」のone_X_valが定義されてないかもとの警告がでる。\n",
    "\n",
    "\n",
    "        if X_val is not None:\n",
    "            one_array = np.ones((X_val.shape[0], 1)) # bias項サンプル数分作成\n",
    "            one_X_val = np.concatenate([one_array, X_val], axis=1) # Xとbias項を結合\n",
    "\n",
    "\n",
    "        for i in range(self.iter):\n",
    "\n",
    "            # 問題1（仮定関数の計算）\n",
    "            # self._linear_hypothesis(x)の中身を書き出し\n",
    "            # self.prediction = one_X @ self.theta\n",
    "            prediction = one_X @ self.theta # losses_val\n",
    "\n",
    "\n",
    "            # 問題2（最急降下法によるパラメータの更新値計算）\n",
    "            # self._gradient_descent(a)の中身を書き出し\n",
    "            # error = self.prediction - y # yはy_train\n",
    "            error = prediction - y # yはy_train\n",
    "            self.theta = self.theta - (self.lr / X.shape[0]) * (error.T @ one_X).T\n",
    "\n",
    "\n",
    "            # 損失計算と記録\n",
    "            prediction = one_X @ self.theta\n",
    "            loss = self._loss_func(y,prediction)\n",
    "            self.losses = np.append(self.losses, loss)\n",
    "\n",
    "\n",
    "            if X_val is not None:\n",
    "                # print(one_X_val.shape)\n",
    "                # print(self.theta.shape)\n",
    "                prediction_val = one_X_val @ self.theta\n",
    "                loss_val = self._loss_func(y_val,prediction_val)\n",
    "                self.losses_val = np.append(self.losses_val, loss_val)\n",
    "\n",
    "\n",
    "            # 問題7（学習曲線のプロット）のグラフ描画時（問題5（損失関数）で作成した関数を使用）\n",
    "            # self._mse(y)\n",
    "            # self._loss_func()\n",
    "\n",
    "    # 問題1\n",
    "    def _linear_hypothesis(self, X):  # 必要に応じて引数を追加して下さい\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "        self.coef_ : theta(coefficient) 次の形のndarray, shape (n_features,)\n",
    "          パラメータ\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "        \"\"\"\n",
    "        # X.shape(n_samples, n_features) shape[0]で行数取得,shape[1]で列数取得\n",
    "        self.n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "\n",
    "        # Xの(n_samples, 1) のshapeの1のみの行列を作る\n",
    "        one_array = np.ones((X.shape[0], 1))\n",
    "\n",
    "        # Xの一列目にone_arrayを結合\n",
    "        self.one_X = np.concatenate([one_array, X], axis=1)\n",
    "\n",
    "        # one_Xの特徴量数の1のみの行列を作る(n_features+1, 1) shape[1]で列数取得\n",
    "        self.prediction = self.one_X @ self.theta\n",
    "\n",
    "\n",
    "    # 問題2\n",
    "    def _gradient_descent(self, X, y):\n",
    "        # _gradient_descent(self, X, y_hat, y_true, alpha= , one_X, n_samples):\n",
    "        \"\"\"\n",
    "        最急降下法によるパラメータの更新値計算\n",
    "        Parameters\n",
    "        ----------\n",
    "        α: 学習率\n",
    "        i : サンプルのインデックス\n",
    "        j : 特徴量のインデックス\n",
    "        lr : alfa アルファ　学習率(learning rate)\n",
    "        self.coef_ : theta(coefficient) 次の形のndarray, shape (n_features,)\n",
    "        Returns\n",
    "        -------\n",
    "        theta\n",
    "        \"\"\"\n",
    "        # y_hatは　_linear_hypothesisのreturnを予定　\n",
    "        # y_trueはどこかの正解値\n",
    "        error = self.prediction - y\n",
    "\n",
    "        # one_Xは　Xの1列目に1のみの列を結合させてある\n",
    "        self.theta = self.theta - (self.lr / self.n_samples) * (error.T @ self.one_X).T\n",
    "\n",
    "    # 問題3\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰での推定\n",
    "        \"\"\"\n",
    "        #  パラメータを決定した後、そのパラメータを用いて、予測結果を出力しなければなりません。これを推定と言います。\n",
    "        one_array = np.ones((X.shape[0], 1))\n",
    "        one_X = np.concatenate([one_array, X], axis=1)\n",
    "        self.prediction = one_X @ self.theta\n",
    "\n",
    "        # return prediction\n",
    "\n",
    "    # 問題4\n",
    "    def _mse(self, y, prediction):\n",
    "        \"\"\"\n",
    "        平均二乗誤差の計算\n",
    "        \"\"\"\n",
    "        mse = ((prediction - y)**2).mean(axis=0)\n",
    "\n",
    "        return mse\n",
    "\n",
    "    # 問題5\n",
    "    def _loss_func(self, y, prediction):\n",
    "        \"\"\"\n",
    "        損失関数\n",
    "        \"\"\"\n",
    "        # 引数のイメージ\n",
    "        # y=1\n",
    "        # prediction=2\n",
    "\n",
    "\n",
    "        # loss = self.mse / 2\n",
    "        # self.losses = np.append(self.losses, loss)\n",
    "        mse = self._mse(y, prediction)\n",
    "        loss = mse / 2\n",
    "\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x7f9557b010f0>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# pd.read_csv()を使用して、変数に格納\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# Xに説明変数GrLivArea(リビングの広さ)とYearBuiltを抽出\n",
    "X_df = train[[\"GrLivArea\", \"YearBuilt\"]]\n",
    "\n",
    "# Yに目的変数SalePriceを抽出\n",
    "Y_df = train[[\"SalePrice\"]]\n",
    "\n",
    "# X_df, Y_dfをconcatメソッドで　axis=1に結合\n",
    "df = pd.concat([X_df, Y_df], axis=1)\n",
    "\n",
    "# DataFrameをndarrayへ変換\n",
    "X_ndarray = X_df.values\n",
    "Y_ndarray = Y_df.values\n",
    "\n",
    "# 前処理の一貫として、訓練データと検証データの分割。今回は訓練データ75%、検証データ25%として分割。\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_ndarray, Y_ndarray, test_size=0.25)\n",
    "\n",
    "\n",
    "scl = StandardScaler()\n",
    "\n",
    "# 標準化（訓練用データで.fitを行う）\n",
    "# fit:パラメータ（平均や標準偏差 etc）計算\n",
    "# fit_transform:パラメータ計算とデータ変換をまとめて実行\n",
    "scl.fit(X_train)\n",
    "\n",
    "# 標準化（訓練用、検証用双方で.transformを行う）\n",
    "# transform:データ変換\n",
    "X_train_transformed = scl.transform(X_train)\n",
    "X_test_transformed = scl.transform(X_test)\n",
    "\n",
    "#-------------------------------　スクラッチ　------------------------------------------------\n",
    "num_iter=2000\n",
    "lr=0.003\n",
    "slr = ScratchLinearRegression(num_iter, lr, no_bias=True, verbose=False)\n",
    "\n",
    "slr.fit(X_train_transformed, Y_train, X_test_transformed, Y_test)\n",
    "Y_test_pred_0 = slr.predict(X_test_transformed)\n",
    "\n",
    "# print(len(slr.losses))\n",
    "# print(len(slr.losses_val))\n",
    "\n",
    "\n",
    "#-------------------------------　sklearn.linear_model　　------------------------------------------------\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "#\n",
    "# # モデルに引数を渡してインスタン化する\n",
    "# lgr = LinearRegression()\n",
    "# #\n",
    "# # # 学習する（訓練用データを.fitする）\n",
    "# lgr.fit(X_train_transformed, Y_train, X_test_transformed, Y_test)\n",
    "# #\n",
    "# # # # 推定する（検証用データを.predictする）\n",
    "# # Y_train_pred = lgr.predict(X_train_transformed)\n",
    "# Y_test_pred_1 = lgr.predict(X_test_transformed)\n",
    "\n",
    "\n",
    "#-------------------------------　描画　------------------------------------------------\n",
    "plt.plot(np.arange(1,len(slr.losses)+1),slr.losses,label='train_loss',linewidth=2)\n",
    "plt.plot(np.arange(1,len(slr.losses_val)+1),slr.losses_val,label='val_loss',linewidth=2)\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}