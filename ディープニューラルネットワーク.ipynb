{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shunnadamoto/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if __name__ == '__main__':\n",
      "/Users/shunnadamoto/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# 読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像データ→行データ\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# 分割(訓練データ・評価データ\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# one-hotベクトル化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_val[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1 全結合層のクラス化\n",
    "\n",
    "#%%\n",
    "\n",
    "class FC:\n",
    "    \"\"\"全結合層\"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        initializer : 初期化インスタンス\n",
    "        optimizer : 勾配更新手法\n",
    "        \"\"\"\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        # 初期化インスタンスの関数実行\n",
    "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = initializer.B(self.n_nodes2)\n",
    "        # 最適化インスタンス\n",
    "        self.optimizer = optimizer\n",
    "        # 勾配更新の際に使用（AdaGradのみ）\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        # 逆伝播時に使用\n",
    "        self.Z = X\n",
    "        # 順伝播計算部分本体\n",
    "        self.A = X @ self.W + self.B\n",
    "        return self.A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 前の層から逆伝播してきた値（活性化関数の逆伝播の値が入ってくる）\n",
    "        \n",
    "        Overview\n",
    "        ----------\n",
    "        前回のSprint9 ニューラルネットワークでは下記のような逆伝播処理になっていた\n",
    "            0 ## 2層目\n",
    "            1 dZ2 = dA3 @ self.W3.T\n",
    "            2 dA2 = dZ2 * (1 - self.tanh_function(self.A2)**2)\n",
    "            3 dW2 = self.Z1.T @ dA2\n",
    "            4 dB2 = np.sum(dA2, axis=0)\n",
    "            5 ## 1層目\n",
    "            6 dZ1 = dA2 @ self.W2.T\n",
    "            7 dA1 = dZ1 * (1 - self.tanh_function(self.A1)**2)\n",
    "            8 dW1 = X.T @ dA1\n",
    "            9 dB1 = np.sum(dA1, axis=0)\n",
    "        勾配の計算\n",
    "            ここでは、活性化関数の逆伝播は別で実装し、その値をこの関数の引数として受け取っているので、\n",
    "            この関数の  dA  は、Sprint9の上記の  dA2  に該当する\n",
    "            よって、上記3,4に該当する処理を書いていけばいい\n",
    "        逆伝播の値の計算\n",
    "            活性化関数の逆伝播に渡してやる値、つまりSprint9の上記の  dZ1  に該当する\n",
    "        重み更新\n",
    "            勾配dB,dWが計算されているので、このインスタンス自身をoptimizerインスタンスのupdate関数に渡してやる\n",
    "            optimizerインスタンスのupdate関数の引数は、layerとなっているので、update関数内では、layer.変数名で\n",
    "            このインスタンスの各種メンバ変数にアクセスできる\n",
    "        \"\"\"\n",
    "        # バイアス項の勾配\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        # バイアス項以外の勾配\n",
    "        self.dW = self.Z.T @ dA\n",
    "        # 逆伝播させる値\n",
    "        self.dZ = dA @ self.W.T\n",
    "        # 重み更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return self.dZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題2　初期化方法のクラス化\n",
    "\n",
    "#%%\n",
    "\n",
    "class SimpleInitializer:\n",
    "    \"\"\"各種重みの初期化\"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        sigma : 重みの初期化の際のガウス分布の標準偏差\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題3　最適化手法のクラス化\n",
    "\n",
    "#%%\n",
    "\n",
    "class SGD:\n",
    "    \"\"\"勾配更新手法\"\"\"\n",
    "    def __init__(self, lr):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr : 学習率\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : FCクラスのインスタンス\n",
    "        \n",
    "        Overview\n",
    "        ----------\n",
    "        FCクラス内のbackward関数内で下記の要に実行されている\n",
    "            0 self.optimizer.update(self)\n",
    "        引数に「FCクラスのインスタンス自身」が入っていることを考えると\n",
    "        layer.dW , layer.dB , layer.Z は「FCクラスのインスタンスのメンバ変数」にアクセスしていると考えられる\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / len(layer.Z)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題4　活性化関数のクラス化\n",
    "\n",
    "#%%\n",
    "\n",
    "class Sigmoid:\n",
    "    \"\"\"シグモイド関数\"\"\"\n",
    "    def forward(self, A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        Z = 1 / (1 + np.exp(-self.A))\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 逆伝播されてきた値\n",
    "        \"\"\"\n",
    "        dA = dZ * ((1 / (1 + np.exp(-self.A))) - (1 / (1 + np.exp(-self.A)))**2)\n",
    "        return dA\n",
    "\n",
    "#%%\n",
    "\n",
    "class Tanh:\n",
    "    \"\"\"tanh関数\"\"\"\n",
    "    def forward(self, A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 逆伝播されてきた値\n",
    "        \"\"\"\n",
    "        dA = dZ * (1 - np.tanh(self.A)**2)\n",
    "        return dA\n",
    "\n",
    "#%%\n",
    "\n",
    "class Softmax:\n",
    "    \"\"\"Softmax関数\"\"\"\n",
    "    def forward(self, A): \n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        return Z\n",
    "        \n",
    "    def backward(self, Z, y):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 出力値\n",
    "        y : 正解データ\n",
    "        \"\"\"\n",
    "        # 逆伝播の値\n",
    "        dA = Z - y\n",
    "        # 損失\n",
    "        loss = - np.sum(y * np.log(Z)) / len(y)\n",
    "        return dA, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題5　ReLUクラスの作成\n",
    "\n",
    "#%%\n",
    "\n",
    "class ReLU:\n",
    "    \"\"\"ReLU関数\"\"\"\n",
    "    def forward(self, A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 逆伝播されてきた値\n",
    "        \"\"\"\n",
    "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
    "        return dA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題6　重みの初期値\n",
    "\n",
    "# 全体の構造としては、`SimpleInitializer`と同じで、W,B関数で、それぞれ初期化された重みを返してやっている\n",
    "\n",
    "#%%\n",
    "\n",
    "class XavierInitializer:\n",
    "    \"\"\"Xavierの初期化クラス\"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        sigma : 使用されていない\n",
    "        \n",
    "        Overview\n",
    "        ----------\n",
    "        なぜ使用されていないのに、引数として受け取っているのか\n",
    "        \n",
    "        初期化クラスは、概略すると、下記のように使用されている\n",
    "        \n",
    "        呼び出しの大元\n",
    "            dnn = ScratchDeepNeuralNetrowkClassifier(initializer=SGD or XavierInitializer or HeInitializer) \n",
    "            \n",
    "        定義部分(ScratchDeepNeuralNetrowkClassifier)\n",
    "            class ScratchDeepNeuralNetrowkClassifier:\n",
    "                def __init__(self,xxx,xxx,xxx,initializer):\n",
    "                    .....\n",
    "                    self.initializer = initializer\n",
    "                    .....\n",
    "                def fit(self,xxx,xxx,xxx):\n",
    "                    self.initializer(self.sigma)\n",
    "        \n",
    "        つまり、\n",
    "        「呼び出しの大元」で、どの初期化クラスが渡されるかわからないので、\n",
    "        初期化クラスによっては、sigmaが必要なものと、別途計算が必要なものがあるので、\n",
    "        同じ呼び出し方をしてやるために、この初期かクラスのコンストラクタでも引数として、sigmaを受け取っている\n",
    "        \n",
    "        同じ呼び出し方をしてやらないのであれば、上記fitは、下記のような書き方でも可能\n",
    "            if initializerのクラス名 == \"SGD\":\n",
    "                self.initializer(self.sigma)\n",
    "            else initializerのクラス名 != \"SGD\":\n",
    "                self.initializer()\n",
    "        \"\"\"\n",
    "        _ = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "        \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B\n",
    "\n",
    "#%%\n",
    "\n",
    "class HeInitializer:\n",
    "    \"\"\"Heの初期化クラス\"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        _ = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題7　最適化手法\n",
    "\n",
    "#%%\n",
    "\n",
    "class AdaGrad:\n",
    "    \"\"\"最適化手法（AdaGrad）\"\"\"\n",
    "    def __init__(self, lr):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr : 学習率\n",
    "        \"\"\"\n",
    "        self.lr = lr \n",
    "    \n",
    "    def update(self, layer):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : layerインスタンス\n",
    "        \"\"\"\n",
    "        layer.HW += layer.dW * layer.dW\n",
    "        layer.HB += layer.dB * layer.dB\n",
    "        delta = 1e-7 # 0割エラー防止のため\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
    "        return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題8　クラスの完成\n",
    "\n",
    "#%%\n",
    "\n",
    "class GetMiniBatch:\n",
    "\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        \"\"\"通常のコンストラクタと同様の働き\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数（画像の1次元データ）\n",
    "        y : 目的変数（ラベル）\n",
    "        batch_size : 必要なミニバッチのデータ数\n",
    "        seed : ランダムシード固定\n",
    "        \"\"\"\n",
    "        # ランダムシードの固定（学習ごとに同じ生成順）\n",
    "        np.random.seed(seed)\n",
    "        # バッチ数のメンバ変数\n",
    "        self.batch_size = batch_size\n",
    "        # データ全体の長さ分のインデックスをランダムに並べ替え\n",
    "        # np.random.permutation:配列をランダムに並べ替え\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        # 並べ替えたインデックスと同じ順番で説明変数と目的変数を並べ替え\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        # データ数をバッチ数で割って、何回呼び出せば、全データを学習したことになるかの判定\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # 何回目の呼び出しか\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        # 全データを学習すればストップ\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        # 並び変えた_X,_yの何番目のインデックスを採用するか\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        # returnする前にカウンタに+1しておく\n",
    "        self._counter += 1\n",
    "        # 説明変数と目的変数を返す\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "\n",
    "#%%\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "\n",
    "    def __init__(self,batch_size=20,n_features=784,n_nodes1 =400,n_nodes2 = 200,n_output =10,lr =0.005,epoch=10,sigma=0.02,optimizer=SGD, initializer=HeInitializer,activater=ReLU,output_activater=Softmax,verbose=True):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : バッチサイズ（default:20)\n",
    "        n_features : 説明変数の数（default:784)\n",
    "        n_nodes1 : 前の層のノード数（default:400)\n",
    "        n_nodes2 : 当該層のノード数（default:200)\n",
    "        n_output : 出力層のノード数（default:10)\n",
    "        sigma : 初期化時のパラメータ（default:0.02)\n",
    "        lr : 学習率（default:0.005)\n",
    "        verbose : 計算過程の出力（default:True)\n",
    "        epoch : 学習回数（default:10)\n",
    "        optimizer : 最適化手法（default:SGD)\n",
    "        initializer : 初期化方法（default:HeInitializer）\n",
    "        activater : 活性化関数（default:ReLU）\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.n_features = n_features \n",
    "        self.n_nodes1 = n_nodes1  \n",
    "        self.n_nodes2 = n_nodes2 \n",
    "        self.n_output = n_output\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.optimizer = optimizer \n",
    "        self.sigma = sigma\n",
    "        self.initializer = initializer \n",
    "        self.activater = activater\n",
    "        self.output_activater = output_activater \n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"学習\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 訓練データの説明変数\n",
    "        y : 訓練データの目的変数\n",
    "        X_val : 評価データの説明変数\n",
    "        y_val : 評価データの目的変数\n",
    "        \"\"\"\n",
    "        # lossの記録用配列\n",
    "        self.loss_train = [] \n",
    "        self.loss_val = [] \n",
    "        # 最適化手法の初期化\n",
    "        optimizer = self.optimizer(self.lr)\n",
    "        # 各層の初期化\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
    "        self.activation1 = self.activater()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
    "        self.activation2 = self.activater()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), optimizer)\n",
    "        self.activation3 = self.output_activater()\n",
    "        \n",
    "        # 学習回数分ループ\n",
    "        for i in range(self.epoch):\n",
    "            # ミニバッチイテレータ生成\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
    "            # ミニバッチイテレータループ\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "                ## 順伝播\n",
    "                # 1層目\n",
    "                A1 = self.FC1.forward(mini_X)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                # 2層目\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                # 3層目\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                \n",
    "                ## 逆伝播\n",
    "                dA3, loss = self.activation3.backward(Z3, mini_y)\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) \n",
    "                \n",
    "            # 過程出力\n",
    "            if self.verbose:\n",
    "                ## 順伝播\n",
    "                # 1層目\n",
    "                A1 = self.FC1.forward(X)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                # 2層目\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                # 3層目\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)      \n",
    "                # 損失計算と記録\n",
    "                loss = self.activation3.backward(Z3, y)[1]\n",
    "                self.loss_train.append(loss)\n",
    "                print('epoch:%d train_loss:%f'%(i,loss))\n",
    "                # 評価データ見る\n",
    "                if X_val is not None:\n",
    "                    ## 順伝播\n",
    "                    # 1層目\n",
    "                    A1 = self.FC1.forward(X_val)\n",
    "                    Z1 = self.activation1.forward(A1)\n",
    "                    # 2層目\n",
    "                    A2 = self.FC2.forward(Z1)\n",
    "                    Z2 = self.activation2.forward(A2)\n",
    "                    # 3層目\n",
    "                    A3 = self.FC3.forward(Z2)\n",
    "                    Z3 = self.activation3.forward(A3)\n",
    "                    # 損失計算と記録\n",
    "                    self.loss_val.append(self.activation3.backward(Z3, y_val)[1])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"予測\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 入力配列\n",
    "        \"\"\"\n",
    "        ## 順伝播\n",
    "        # 1層目\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        # 2層目\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        # 3層目\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        # 最も大きいインデックスを採用\n",
    "        return np.argmax(Z3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shunnadamoto/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:1.325126\n",
      "epoch:1 train_loss:0.830070\n",
      "epoch:2 train_loss:0.621605\n",
      "epoch:3 train_loss:0.513638\n",
      "epoch:4 train_loss:0.449630\n",
      "epoch:5 train_loss:0.405368\n",
      "epoch:6 train_loss:0.372098\n",
      "epoch:7 train_loss:0.347720\n",
      "epoch:8 train_loss:0.325894\n",
      "epoch:9 train_loss:0.314186\n",
      "epoch:10 train_loss:0.296136\n",
      "epoch:11 train_loss:0.281415\n",
      "epoch:12 train_loss:0.276707\n",
      "epoch:13 train_loss:0.259010\n",
      "epoch:14 train_loss:0.253429\n",
      "epoch:15 train_loss:0.239743\n",
      "epoch:16 train_loss:0.230993\n",
      "epoch:17 train_loss:0.224728\n",
      "epoch:18 train_loss:0.216890\n",
      "epoch:19 train_loss:0.210665\n",
      "epoch:20 train_loss:0.205702\n",
      "epoch:21 train_loss:0.195459\n",
      "epoch:22 train_loss:0.190220\n",
      "epoch:23 train_loss:0.184307\n",
      "epoch:24 train_loss:0.177610\n",
      "epoch:25 train_loss:0.173838\n",
      "epoch:26 train_loss:0.169237\n",
      "epoch:27 train_loss:0.166084\n",
      "epoch:28 train_loss:0.158714\n",
      "epoch:29 train_loss:0.157510\n",
      "epoch:30 train_loss:0.148897\n",
      "epoch:31 train_loss:0.146653\n",
      "epoch:32 train_loss:0.140905\n",
      "epoch:33 train_loss:0.137274\n",
      "epoch:34 train_loss:0.133330\n",
      "epoch:35 train_loss:0.129493\n",
      "epoch:36 train_loss:0.126732\n",
      "epoch:37 train_loss:0.123265\n",
      "epoch:38 train_loss:0.119445\n",
      "epoch:39 train_loss:0.117560\n",
      "epoch:40 train_loss:0.114309\n",
      "epoch:41 train_loss:0.109612\n",
      "epoch:42 train_loss:0.107170\n",
      "epoch:43 train_loss:0.105777\n",
      "epoch:44 train_loss:0.102190\n",
      "epoch:45 train_loss:0.099033\n",
      "epoch:46 train_loss:0.096235\n",
      "epoch:47 train_loss:0.093614\n",
      "epoch:48 train_loss:0.091843\n",
      "epoch:49 train_loss:0.089250\n",
      "epoch:50 train_loss:0.086481\n",
      "epoch:51 train_loss:0.084440\n",
      "epoch:52 train_loss:0.082750\n",
      "epoch:53 train_loss:0.083866\n",
      "epoch:54 train_loss:0.078704\n",
      "epoch:55 train_loss:0.077967\n",
      "epoch:56 train_loss:0.074341\n",
      "epoch:57 train_loss:0.073023\n",
      "epoch:58 train_loss:0.071282\n",
      "epoch:59 train_loss:0.069064\n",
      "epoch:60 train_loss:0.067225\n",
      "epoch:61 train_loss:0.066166\n",
      "epoch:62 train_loss:0.064571\n",
      "epoch:63 train_loss:0.062289\n",
      "epoch:64 train_loss:0.060245\n",
      "epoch:65 train_loss:0.059818\n",
      "epoch:66 train_loss:0.057941\n",
      "epoch:67 train_loss:0.056226\n",
      "epoch:68 train_loss:0.054908\n",
      "epoch:69 train_loss:0.053999\n",
      "epoch:70 train_loss:0.053122\n",
      "epoch:71 train_loss:0.051738\n",
      "epoch:72 train_loss:0.050272\n",
      "epoch:73 train_loss:0.048755\n",
      "epoch:74 train_loss:0.048590\n",
      "epoch:75 train_loss:0.046340\n",
      "epoch:76 train_loss:0.045157\n",
      "epoch:77 train_loss:0.044244\n",
      "epoch:78 train_loss:0.043775\n",
      "epoch:79 train_loss:0.042087\n",
      "epoch:80 train_loss:0.041069\n",
      "epoch:81 train_loss:0.040247\n",
      "epoch:82 train_loss:0.039341\n",
      "epoch:83 train_loss:0.038357\n",
      "epoch:84 train_loss:0.037787\n",
      "epoch:85 train_loss:0.036722\n",
      "epoch:86 train_loss:0.036068\n",
      "epoch:87 train_loss:0.035310\n",
      "epoch:88 train_loss:0.034721\n",
      "epoch:89 train_loss:0.034138\n",
      "epoch:90 train_loss:0.032890\n",
      "epoch:91 train_loss:0.032488\n",
      "epoch:92 train_loss:0.031817\n",
      "epoch:93 train_loss:0.030910\n",
      "epoch:94 train_loss:0.030220\n",
      "epoch:95 train_loss:0.029611\n",
      "epoch:96 train_loss:0.029069\n",
      "epoch:97 train_loss:0.028469\n",
      "epoch:98 train_loss:0.027870\n",
      "epoch:99 train_loss:0.027439\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 問題9　学習と推定\n",
    "\n",
    "#%%\n",
    "\n",
    "dnn = ScratchDeepNeuralNetrowkClassifier(epoch=100) \n",
    "\n",
    "dnn.fit(X_train[:4000], y_train_one_hot[:4000], X_val[:2000], y_test_one_hot[:2000])\n",
    "\n",
    "#%%\n",
    "\n",
    "pred = dnn.predict(X_val)\n",
    "accuracy_score(y_val, pred)\n",
    "\n",
    "#%%\n",
    "\n",
    "plt.plot(list(range(1, dnn.epoch+1)), dnn.loss_train, label='train')\n",
    "plt.plot(list(range(1, dnn.epoch+1)), dnn.loss_val, label='test')\n",
    "plt.legend()\n",
    "plt.xticks(list(range(1, dnn.epoch+1)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
